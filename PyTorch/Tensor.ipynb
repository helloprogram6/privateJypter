{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 构造一个2*3的矩阵，不初始化\n",
    "print(torch.empty(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1257, 0.6754, 0.7611],\n",
      "        [0.0973, 0.4560, 0.9570]])\n"
     ]
    }
   ],
   "source": [
    "# 构造一个随机初始化的矩阵\n",
    "print(torch.rand(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 构造一个矩阵全为 0，而且数据类型是 long.\n",
    "print(torch.zeros(2,3,dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "## 构造一个张量，直接使用数据\n",
    "print(torch.tensor([5.5,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2354, 0.8545, 0.7127, 0.8176],\n",
      "        [0.6332, 0.6257, 0.8886, 0.7906]], dtype=torch.float64)\n",
      "tensor([[0.1845, 0.4012, 0.7029, 0.3101],\n",
      "        [0.1659, 0.3938, 0.3084, 0.4130]])\n"
     ]
    }
   ],
   "source": [
    "## 根据已有的tensor建立新的tensor\n",
    "x = torch.rand(2,4,dtype=torch.double) \n",
    "print(x)\n",
    "print(torch.rand_like(x,dtype=torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7562, 0.8912, 0.1928],\n",
      "        [0.8978, 0.6429, 0.6057]])\n",
      "tensor([[0.9988, 0.4427, 0.7222],\n",
      "        [0.0299, 0.3176, 0.9730]])\n",
      "tensor([[1.7549, 1.3339, 0.9150],\n",
      "        [0.9277, 0.9605, 1.5787]])\n",
      "tensor([[1.7549, 1.3339, 0.9150],\n",
      "        [0.9277, 0.9605, 1.5787]])\n"
     ]
    }
   ],
   "source": [
    "# 加法\n",
    "x = torch.rand(2,3)\n",
    "y = torch.rand(2,3)\n",
    "print(x)\n",
    "print(y)\n",
    "print(x+y)\n",
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9988, 0.4427, 0.7222],\n",
      "        [0.0299, 0.3176, 0.9730]])\n",
      "tensor([[1.7549, 1.3339, 0.9150],\n",
      "        [0.9277, 0.9605, 1.5787]])\n"
     ]
    }
   ],
   "source": [
    "# 把x加到y上 【关于tensor的原地操作函数都有一个后缀‘_’，例如y.add_(x);y.copy_(y)】\n",
    "print(y)\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9605) tensor([[0.9277, 0.9605, 1.5787]]) tensor([1.3339, 0.9605])\n"
     ]
    }
   ],
   "source": [
    "# 输出 第2行第2列；第2行；第2列\n",
    "print(y[1][1],y[1:2],y[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tensor与NumPy数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "## tensor 转化为 numpy数组\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# 当修改a的值，b的值也在跟着变化，说明a与b共享底层内存位置\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# numpy转化为Tensor 【CPU上的所有张量(CharTensor除外)都支持与Numpy的相互转换】\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out = a)// a和b是共享内存空间的。如果是 a = a+1的话，a和b是不共享内存空间的\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA Tensors\n",
    "# torch.cuda.is_available() 判断是否有 gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# tensor变量使用 .to方法可以放到 device 上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
